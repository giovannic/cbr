\documentclass[11pt]{article}
\usepackage{a4, fullpage}
\usepackage{bibtopic}
\usepackage[small,compact]{titlesec}
\usepackage{float}
\usepackage{amssymb,amsmath}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{multicol}
\restylefloat{table}
%\usepackage{parskip}
%\usepackage{setspace}




\setlength{\parskip}{0.3cm}
\setlength{\parindent}{0cm}
\setlength{\textheight}{10in}
\setlength{\textwidth}{6.5in}
\setlength{\parskip}{2pt}
\addtolength{\oddsidemargin}{-.3in}
\addtolength{\evensidemargin}{-.3in}
\addtolength{\topmargin}{-.6in}
\addtolength{\textwidth}{.6in}

\begin{document}



\title{Assignment 4\\ Case Based Reasoning \\ Group 30  }

\author{John Walker \and Adam Fiksen \and Giovanni Charles }

\date{\today}         % inserts today's date

\maketitle           % generates the title from the data above


\section{Results}
% Confuction matrices (for both types of networks)
% Average classification rate and recall, precision and F1 measures per class (part VIII).

\subsection{Confusion Matricies}

\begin{table}[H]
\caption{Average Confusion Matrix} % title of Table
\centering % used for centering table
\begin{tabular}{c c c c c c} % centered columns (4 columns)
\hline % inserts single horizontal line
0  & 0   & 0   & 0   & 0  & 0   \\ % inserting body of the table
0  & 0   & 0   & 0   & 0  & 0   \\
0  & 0   & 0   & 0   & 0  & 0   \\
0  & 0   & 0   & 0   & 0  & 0   \\
0  & 0   & 0   & 0   & 0  & 0   \\ 
0  & 0   & 0   & 0   & 0  & 0 \\ [1ex] % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\label{table:conf} % is used to refer this table in the text
\end{table}


\subsection{Average Classification Rate, Recall Precision and F1 Measures}

\begin{table}[H]
\caption{Average Evaluation Results} % title of Table
\centering % used for centering table
\begin{tabular}{c c c c c} % centered columns (4 columns)
\hline\hline %inserts double horizontal lines
Emotion & name & Precision rate & Recall rate & f1 measure\\ [0.5ex] % inserts table
\hline % inserts single horizontal line
1 & anger     & 0 & 0 & 0\\ % inserting body of the table
2 & disgust   & 0 & 0 & 0\\
3 & fear      & 0 & 0 & 0\\
4 & happiness & 0 & 0 & 0\\
5 & sadness   & 0 & 0 & 0\\ 
6 & suprise   & 0 & 0 & 0\\ [1ex] % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\label{table:sixevaluation} % is used to refer this table in the text
\end{table}

Classification Rate: 0.0000


\section{Implementation Details}
\section{Questions}

\subsection{How did you solve the problem of finding two or more best matches with different labels in function RETRIEVE?}

Our chosen similarity measure returns a floating point number which means 2 similarities are 
never equal, therefore there are no two best matches.

\subsection{Discuss what happens if you try to add a case to CBR system that is already there (either in the initialisation phase or when you call the retain function? How did you deal with this issue?}

If we add a duplicate value, we recompute the similarities for all elements in that cluster.
For all elements in that cluster, we multiply current average similarity by n, 
the number of items in the structure, and add
the similarity with the duplicate node, before dividing by n+1. This ensures the duplicate
value is taken into account whilst not wasting space in the cluster.

\subsection{Compare the different similarity measures you have used (at least three). What are the advantages / disadvantages of each measure?}

The similarity measures we used are: length of AU vector, euclidean distance between points, 
cosine similarity.

We thought length of AU vector was a fairly poor measure of similarity -- though it was the
quickest and simplest measure to calculate, it would have very poor accuracy. This can be seen
by comparing the AU vectors [1..22] and [23..44]. These two cases are clearly very
dissimilar in terms of AUs enabled, only matching on 1 feature, however their lengths are
the same so there would be a high similarity given to these two vectors.

Euclidean distance is a measure we thought would give a high similarity accuracy. It
effectively plots the points of the AU vectore represented as a bit array
on an n-dimensional graph and calculates the
distance between them. This is the method used in numerous published books and papers
to find the nearest neighbours of a point so we assumed it would be a good measure of
similarity. We were surprised to find that the euclidean distance actually performed 
worse than other measures (e.g. cosine similarity). This could be put down to the effect
noise could have on the distance the points are from each other.

Cosine similarity works by calculating the cosine of the angle between the two AU vectors
(represented as a bit array). This measure is valuable in systems which must 
`measure cohesion within clusters in the field of data mining'. The cosine similarity
seems to work exceptionally well, giving a high accuracy rating (as seen elsewhere in this
report)

\subsection{Describe how you initialise your CBR system.}

\subsection{CBR belongs to a specific class of learning algorithms? How are these algorithms called and what are the differences with other learning algorithms, like neural networks and decision trees?}

CBR belongs to the lazy learning class of learning algorithms. This means that, unlike eager
learning algorithms, CBR systems don't generate a global hypothesis of the target function at
creation time, but rather generate local hypotheses of the function each time a new case is
presented. This results in lazy methods requiring less computation when training, but more
when a new case is passed in. Further to this, and perhaps more crucially, because eager
algorithms estimate the target function without knowledge of new cases, it is unable to tailor
the hypothesis to any new cases. By comparison, a lazy learning algorithm has the new case
available, thus it is able to create a hypothesis for the target function that is specifically
suited to this new case. Lazy learning is able to choose multiple different hypotheses out of
the hypthesis space dependant on the input, whereas eager is fixed to its single hypothesis.


\section{Code Flow Charts}

\end{document}
